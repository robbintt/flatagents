# Recursive Language Model (RLM) Example

A FlatMachine-based implementation of Recursive Language Models for handling arbitrarily long contexts.

Based on **arXiv:2512.24601** - "Recursive Language Models" by Zhang, Kraska, and Khattab.

## Overview

RLMs enable LLMs to process inputs far beyond their native context windows (tested up to 10M+ tokens) through:

1. **REPL Exploration**: The full context is stored as an external variable (`INPUT`) in a Python REPL that the LLM can programmatically interact with
2. **Recursive Decomposition**: Complex tasks are broken into sub-tasks that can be processed independently
3. **Parallel Processing**: Sub-tasks are processed concurrently via FlatMachine's `foreach` parallelism
4. **Synthesis**: Results are aggregated into a final answer

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     RLM Main Machine                        │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────┐    ┌────────────┐    ┌─────────────────────┐  │
│  │  START  │───>│  EXPLORE   │───>│     DECOMPOSE       │  │
│  └─────────┘    │  (REPL)    │    │  (Plan sub-tasks)   │  │
│                 └────────────┘    └──────────┬──────────┘  │
│                      ↑  ↓                    │             │
│                 ┌────────────┐               │             │
│                 │  EXECUTE   │               │             │
│                 │  (Code)    │               ↓             │
│                 └────────────┘    ┌─────────────────────┐  │
│                                   │  PROCESS CHUNKS     │  │
│                                   │  (foreach parallel) │  │
│  ┌─────────┐    ┌────────────┐    └──────────┬──────────┘  │
│  │  DONE   │<───│ SYNTHESIZE │<──────────────┘             │
│  └─────────┘    └────────────┘                             │
└─────────────────────────────────────────────────────────────┘
```

## Key Components

### Agents

| Agent | Purpose |
|-------|---------|
| `explorer.yml` | Generates Python code to explore the context via REPL |
| `decomposer.yml` | Breaks complex tasks into independent sub-tasks |
| `processor.yml` | Processes a single chunk to answer a sub-task |
| `synthesizer.yml` | Combines sub-task results into final answer |

### Machines

| Machine | Purpose |
|---------|---------|
| `machine.yml` | Main orchestrator - explore, decompose, synthesize |
| `chunk_processor_machine.yml` | Processes individual chunks (called via foreach) |

### Hooks

| Hook Class | Actions |
|------------|---------|
| `RLMHooks` | `init_repl`, `execute_repl`, `log_error` |
| `ChunkProcessorHooks` | `extract_chunk`, `log_chunk_error` |

## Usage

### Quick Start

```bash
# Run the demo
./run.sh

# Or with Python directly
python -m rlm.main --demo
```

### Process a File

```bash
# Answer a question about a long document
./run.sh --file document.txt --task "What are the main conclusions?"

# With custom chunk size
./run.sh --file data.json --task "Count all error entries" --chunk-size 8000
```

### Interactive Mode

```bash
./run.sh --interactive
```

### Programmatic Usage

```python
import asyncio
from rlm.main import run_rlm

async def main():
    # Load your long context
    with open("large_document.txt") as f:
        context = f.read()

    # Run RLM
    result = await run_rlm(
        context=context,
        task="What is the total revenue mentioned across all quarterly reports?",
        max_chunk_size=16000,
        max_exploration_rounds=5
    )

    print(f"Answer: {result['answer']}")
    print(f"Confidence: {result['confidence']}")
    print(f"Method: {result['method']}")

asyncio.run(main())
```

## How It Works

### 1. Exploration Phase

The explorer agent writes Python code to understand the context structure:

```python
# Example exploration code generated by the LLM
print(f"Total length: {len(INPUT)}")
print(f"First 500 chars: {INPUT[:500]}")
print(f"Number of lines: {len(INPUT.split(chr(10)))}")

# Search for relevant sections
import re
matches = re.findall(r'Section \d+:', INPUT)
print(f"Found {len(matches)} sections")
```

### 2. Decomposition Phase

The decomposer analyzes findings and creates sub-tasks:

```yaml
sub_tasks:
  - id: "task_1"
    question: "What is the revenue in Q1?"
    chunk_start: 0
    chunk_end: 15000
    contribution: "First quarter data"

  - id: "task_2"
    question: "What is the revenue in Q2?"
    chunk_start: 15000
    chunk_end: 30000
    contribution: "Second quarter data"
```

### 3. Processing Phase

Each sub-task is processed in parallel via the chunk processor machine.

### 4. Synthesis Phase

Results are aggregated according to the strategy (concat, sum, vote, synthesize).

## Configuration

### Model Profiles

Edit `config/profiles.yml` to configure models:

```yaml
data:
  model_profiles:
    default:
      provider: cerebras
      name: zai-glm-4.7
      temperature: 1.0

    creative:
      provider: cerebras
      name: zai-glm-4.7
      temperature: 0.6

  default: default
```

### Machine Settings

Adjust in `config/machine.yml`:

```yaml
settings:
  max_steps: 50              # Safety limit on state transitions
  parallel_fallback: sequential  # Fallback if parallel fails
```

## Performance Characteristics

Based on the original RLM paper:

| Benchmark | Base LLM | Summarization | RLM |
|-----------|----------|---------------|-----|
| S-NIAH (Needle in Haystack) | ~60% | ~70% | >95% |
| BrowseComp-Plus (Multi-hop QA) | <5% | ~25% | >55% F1 |
| OOLONG Linear (Aggregation) | ~40% | ~50% | >85% |
| OOLONG Pairs (Quadratic) | ~20% | ~30% | >70% |

## File Structure

```
rlm/
├── config/
│   ├── machine.yml              # Main RLM machine
│   ├── chunk_processor_machine.yml  # Chunk processor
│   ├── profiles.yml             # Model configurations
│   ├── explorer.yml             # REPL exploration agent
│   ├── decomposer.yml           # Task decomposition agent
│   ├── processor.yml            # Chunk processing agent
│   └── synthesizer.yml          # Result synthesis agent
├── src/rlm/
│   ├── __init__.py
│   ├── main.py                  # CLI entry point
│   ├── hooks.py                 # FlatMachine hooks
│   └── repl.py                  # REPL executor
├── pyproject.toml
├── run.sh
└── README.md
```

## References

- **Paper**: [arXiv:2512.24601](https://arxiv.org/abs/2512.24601) - "Recursive Language Models"
- **Official Repo**: [github.com/alexzhang13/rlm](https://github.com/alexzhang13/rlm)
- **Blog Post**: [alexzhang13.github.io/blog/2025/rlm](https://alexzhang13.github.io/blog/2025/rlm/)

## License

This example is provided as part of the FlatAgents SDK examples.
