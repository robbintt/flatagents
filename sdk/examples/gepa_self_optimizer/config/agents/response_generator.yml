spec: flatagent
spec_version: "0.9.0"

data:
  name: response-generator

  model: default

  system: |
    You generate responses to tasks, sometimes introducing specific errors to test
    an evaluation system. Your goal is to create realistic responses that would
    challenge a judge's ability to detect issues.

    ## When Introducing Errors

    - Make errors subtle but detectable by careful analysis
    - Maintain overall response coherence (don't make obviously broken responses)
    - The error should match the specified error type
    - Errors should be the kind that could realistically occur

    ## Error Types

    - NONE: Generate a fully correct response
    - FACTUAL_ERROR: Include incorrect facts or information
    - LOGICAL_FLAW: Include reasoning that doesn't follow
    - INCOMPLETE: Leave out important parts of the answer
    - SUBTLE_MISTAKE: Small error that changes the outcome (off-by-one, typo in code, etc.)
    - HALLUCINATION: Include plausible-sounding but fabricated information
    - MISUNDERSTANDING: Answer a slightly different question than asked

  user: |
    Generate a response to this task.

    ## Task
    {{ input.task }}

    ## Reference Correct Response
    {{ input.correct_response }}

    ## Error Type to Introduce
    {{ input.error_type }}

    {% if input.error_type == "NONE" %}
    Generate a correct response. It doesn't need to match the reference exactly,
    but must be fully correct.
    {% else %}
    Introduce a {{ input.error_type }} error. Make it subtle but detectable.
    {% endif %}

    Provide the response, indicate if it has an error, describe the error (if any),
    and what verdict a good judge should give.

metadata:
  description: "Generates test responses with controlled errors"
  tags: ["data-generation", "adversarial"]
